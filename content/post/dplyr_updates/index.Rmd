---
title: "Ten Tidyverse Updates"
author: "Jim Gruman"
date: "2020-09-01"
diagram: true
output: 
 blogdown::html_page:
  toc: false
categories: [Data Science, R]
description: "Stay up to date with examples using the penguins dataset" 
# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image: 
  caption: ''
  focal_point: "Smart"
  preview_only: false
featured: false
draft: false
---

There is no doubt that the `tidyverse` opinionated collection of R packages offers attractive, intuitive ways of wrangling data for data science. In earlier versions of `tidyverse` some elements of user control were sacrificed in favor of simplifying functions that could be picked up and easily used by rookies. In the 2020 updates to `dplyr` and `tidyr` there has been progress to restoring some finer control.

This means that there are new methods available in the `tidyverse` that some may not be aware of. The methods allow you to better transform your data directly to the way you want and to perform operations more flexibly. They also provide new ways to perform common tasks like nesting, modeling and graphing in ways where the code is more readable. Often users are only just scratching the surface of what can be done with the latest updates to this important set of packages.

Itâ€™s incumbent on any analyst to stay up to date with new methods. This post covers ten examples of approaches to common data tasks that are better served by the latest `tidyverse` updates. We will use the new Palmer Penguins dataset, a great all round dataset for illustrating data wrangling.

First letâ€™s load our `tidyverse` packages and the Palmer Penguins dataset and take a quick look at it. Please be sure to install the latest versions of these packages before trying to replicate the work here.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      cache=TRUE, 
                      dev = 'jpeg',
                      fig.width = 9,
                      fig.height = 6,
                      out.width = '100%')

ggplot2::theme_set(ggplot2::theme_minimal())
```

```{r libraries}
library(tidyverse)
library(palmerpenguins)

penguins <-palmerpenguins::penguins  %>%
           filter(!is.na(bill_length_mm))

penguins
```

The dataset presents several observations of anatomical parts of penguins of different species, sexes and locations, and the year that the measurements were taken.

## 1. Selecting columns

`tidyselect` helper functions are now built in to allow you to save time by selecting columns using `dplyr::select()` based on common conditions. In this case, if we want to reduce the dataset to just bill measurements we can use this, noting that all measurement columns contain an underscore:

```{r}
penguins %>% 
  dplyr::select(!contains("_"), starts_with("bill"))
```

A full set of `tidyselect` helper functions can be found in the documentation [here](https://cran.r-project.org/web/packages/tidyselect/tidyselect.pdf).

## 2. Reordering columns

`dplyr::relocate()` allows a new way to reorder specific columns or sets of columns. For example, if we want to make sure that all of the measurement columns are at the end of the dataset, we can use this, noting that my last column is year:

```{r}
penguins <- penguins %>% 
  dplyr::relocate(contains("_"), .after = year)

penguins
```

Similar to `.after` you can also use `.before` as an argument here.

## 3. Controlling mutated column locations

Note in the `penguins` dataset that there are no unique identifiers for each study group. This can be problematic when we have multiple penguins of the same species, island, sex and year in the dataset. To address this and prepare for later examples, letâ€™s add a unique identifier using `dplyr::mutate()`, and here we can illustrate how `mutate()` now allows us to position our new column in a similar way to `relocate()`:

```{r}
penguins_id <- penguins %>% 
  dplyr::group_by(species, island, sex, year) %>% 
  dplyr::mutate(studygroupid = row_number(), .before = contains("_"))

penguins_id
```

## 4. Transforming from wide to long

The `penguins` dataset is clearly in a wide form, as it gives multiple observations across the columns. For many reasons we may want to transform data from wide to long. In long data, each observation has its own row. The older function `gather()` in `tidyr` was popular for this sort of task but its new version `pivot_longer()` is even more powerful. In this case we have different body parts, measures and units inside these column names, but we can break them out very simply like this:

```{r}
penguins_long <- penguins_id %>% 
  tidyr::pivot_longer(contains("_"), # break out the measurement cols
                      names_to = c("part", "measure", "unit"), # break them into these three columns
                      names_sep = "_") #  use the underscore to separate

penguins_long
```

## 5. Transforming from long to wide

Itâ€™s just as easy to move back from long to wide. `pivot_wider()` gives much more flexibility compared to the older `spread()`:

```{r}
penguins_wide <- penguins_long %>% 
  tidyr::pivot_wider(names_from = c("part", "measure", "unit"), # pivot these columns
                     values_from = "value", # take the values from here
                     names_sep = "_") # combine col names using an underscore

penguins_wide
```

## 6. Running group statistics across multiple columns

`dplyr` can how apply multiple summary functions to grouped data using the `across` adverb, helping you be more efficient. If we wanted to summarize all bill and flipper measurements in our penguins we would do this:

```{r}
penguin_stats <- penguins %>% 
  dplyr::group_by(species) %>% 
  dplyr::summarize(across(ends_with("mm"), # do this for any column ending in mm
                          list(~mean(.x, na.rm = TRUE), ~sd(.x, na.rm = TRUE)))) # calculate a mean and sd

penguin_stats
```

## 7. Control how output columns are named when summarising across multiple columns

The columns in `penguin_stats` have been given default names which are not that intuitive. If we name our summary functions, we can then use the `.names` argument to control precisely how we want these columns named. This uses `glue` notation. For example, here we want to construct the new column names by taking the existing column names, removing any underscores or â€˜mmâ€™ metrics, and pasting to the summary function name using an underscore:

```{r}
penguin_stats <- penguins %>% 
  dplyr::group_by(species) %>% 
  dplyr::summarize(across(ends_with("mm"), 
                          list(mean = ~mean(.x, na.rm = TRUE), sd = ~sd(.x, na.rm = TRUE)), # name summary functions
                          .names = "{gsub('_|_mm', '', col)}_{fn}")) # structure for summarized column names

penguin_stats
```

## 8. Running models across subsets

The output of `summarize()` can now be literally anything, because `dplyr` now allows different column types. We can generate summary vectors, dataframes or other objects like models or graphs.

If we wanted to run a model for each species you could do it like this:

```{r, warning=FALSE}
penguin_models <- penguins %>% 
  dplyr::group_by(species) %>% 
  dplyr::summarize(model = list(lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm)))  # store models in a list column

penguin_models
```

Itâ€™s not usually that useful to keep model objects in a dataframe, but we could use other tidy-oriented packages to summarize the statistics of the models and return them all as nicely integrated dataframes:

```{r, warning=FALSE}
library(broom)

penguin_models <- penguins %>% 
  dplyr::group_by(species) %>% 
  dplyr::summarize(broom::glance(lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm))) # summarize model stats

penguin_models
```

## 9. Nesting data

Often we have to work with subsets, and it can be useful to apply a common function across all subsets of the data. For example, maybe we want to take a look at our different species of penguins and make some different graphs of them. Grouping based on subsets would previously be achieved by the following somewhat awkward combination of `tidyverse` functions.

```{r}
penguins %>% 
  dplyr::group_by(species) %>% 
  tidyr::nest() %>% 
  dplyr::rowwise()
```

The new function `nest_by()` provides a more intuitive way to do the same thing:

```{r}
penguins %>% 
  nest_by(species)
```

The nested data will be stored in a column called `data` unless we specify otherwise using a `.key` argument.

## 10. Graphing across subsets

Armed with `nest_by()` and the fact that we can summarize or mutate virtually any type of object now, this allows us to generate graphs across subsets and store them in a dataframe for later use. Letâ€™s scatter plot bill length and depth for our three penguin species:

```{r}
# generic function for generating a simple scatter plot in ggplot2
scatter_fn <- function(df, col1, col2, title) {
  df %>% 
    ggplot2::ggplot(aes(x = {{col1}}, y = {{col2}})) +
    ggplot2::geom_point() +
    ggplot2::geom_smooth(method = "loess", formula = "y ~ x") +
    ggplot2::labs(title = title)
}

# run function across species and store plots in a list column
penguin_scatters <- penguins %>% 
  dplyr::nest_by(species) %>% 
  dplyr::mutate(plot = list(scatter_fn(data, bill_length_mm, bill_depth_mm, species))) 

penguin_scatters
```

Now we can easily display the different scatter plots to show, for example, that our penguins exemplify [Simpsonâ€™s Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox):

```{r}
library(patchwork)

# generate scatter for entire dataset
p_all <- scatter_fn(penguins, bill_length_mm, bill_depth_mm, "All Species") 

# get species scatters from penguin_scatters dataframe
for (i in 1:3) {
 assign(paste("p", i, sep = "_"),
        penguin_scatters$plot[i][[1]]) 
}

# display nicely using patchwork in R Markdown
p_all /
(p_1 | p_2 | p_3) +
  plot_annotation(caption = "{palmerpenguins} dataset")
```

> Inspired by Keith McNulty's post  [here](https://towardsdatascience.com/ten-up-to-date-ways-to-do-common-data-tasks-in-r-4f15e56c92d)

----

### Did you find this page helpful? Consider sharing it ðŸ™Œ





