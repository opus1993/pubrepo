---
date: "2019-12-29"
diagram: true
image: 
  caption: 'Image credit: [**Nikhita S @kryptonitenicky**](https://unsplash.com/photos/NsPDiPFTp4c)'
  placment: 3
markup: goldmark
math: true
title: Learning to Teach Machines
author: Jim Gruman
projects: []
slug: learning-to-teach-machines
categories:
  - R
tags:
  - Education
---

Alison Hill recently shared a valuable list of learning resources, organized roughly in the order they are most helpful for students of Machine Learning. 

{{< figure src="./7w1.jpg" title="" lightbox="true" >}}

----

[A Visual Introduction to Machine Learning by r2d3](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). This is a wonderfuly simple two-part series:

[Part I: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)

[Part II: Model Tuning and the Bias-Variance Tradeoff](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)

----

[Supervised Machine Learning by Julia Silge](https://supervised-ml-course.netlify.com/)
Now taught with R and the `tidymodels` package, this is a solid next step in your machine learning journey as you‚Äôll start doing ML right away in your browser using an innovative course delivery platform. You‚Äôll also get to play with data that is not iris, titanic, or AmesHousing. 

----

[Hands on Machine Learning in R](https://bradleyboehmke.github.io/HOML/) by Bradley Boehmke & Brandon Greenwell. Another great way to learn concepts plus code that focuses on the caret package. Each chapter maps onto a new learning algorithm and provides a code-through with real data from building to tuning. The authors also offer practical advice for each algorithm, and the ‚Äúfinal thoughts‚Äù sections at the end of each chapter will help you tie it all together.

----

[Interpretable Machine Learning: A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/) the whole book is well-written.

----

*Model evaluation, model selection, and algorithm selection in machine learning* is a 4-part series by Sebastian Raschka. This is a a great evidence-based, thorough overview of the methods for machine learning. Alison noted that he walks you step-by-step from the simplest methods like the holdout method up to nested cross-validation:

- [Part 1: The Basics](https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html)
- [Part 2: Bootstrapping and Uncertainties](https://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html)
- [Part 3: Cross-validation and hyperparameter tuning](https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html)
- [Part 4: Part IV - Comparing the performance of machine learning models and algorithms using statistical tests and nested cross-validation](https://sebastianraschka.com/blog/2018/model-evaluation-selection-part4.html)

----

At this point, if you can read through the above resources and you are no longer feeling awash in new terminology, your vocabulary and mental model are in pretty good shape! That means you are ready for the next step, which is to read Max Kuhn and Kjell Johnson‚Äôs new book:

[Feature Engineering and Selection: A Practical Approach for Predictive Models](http://www.feat.engineering/)

------

[April Hill's post](https://alison.rbind.io/post/2019-12-23-learning-to-teach-machines-to-learn/)

### Did you find this page helpful? Consider sharing it üôå



