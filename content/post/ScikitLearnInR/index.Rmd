---
date: "2020-04-22"
diagram: true
# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image: 
  caption: ''
  focal_point: "Smart"
  preview_only: true
title: 'Scikit Learn in R'
author: "Jim Gruman"
output: 
 blogdown::html_page:
  toc: false
categories: [Python, Data Science, R]
description: "Setup to Run Python in RStudio"
featured: false
draft: false
---

>Inspired by [Matt Dancho's Business-Science Learning Series post](https://www.business-science.io/learn-r/2020/04/20/setup-python-in-r-with-rmarkdown.html)

The 2 most popular data science languages - `Python` and `R` - are often characterized as rivals. This couldnâ€™t be further from the truth. Data scientists use the strengths of each language environment. For Example:

- **Machine Learning**: They can switch to Python to leverage Scikit Learn and PyTorch.

- **Data Wrangling, Visualization, Apps & Reporting**: They can quickly change to R to use `tidyverse`, `shiny` and `rmarkdown`.

The bottom line is that knowing both R and Python makes teams much more productive. 

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)
```

This post is a quick demonstration of the setup and creation of an environment to use Python from within the RStudio IDE using the `reticulate` package.

Step 1: Install the Anaconda distribution. As of today, Anaconda still ships with python 3.7. On Windows, only the 32-bit Python installer can be made to work with `reticulate`. 

Step 2: Install the `reticulate` R package

```{r}
library(tidyverse)
library(lubridate)
library(stringr)
library(reticulate)
theme_set(theme_minimal())
```

Run the following code at the anaconda prompt:

>`conda update --all`

>`conda create -n py3.7 python=3.7 scikit-learn pandas numpy matplotlib`

>`conda activate py3.7`

>`python --version`

List your Conda Environments, from RStudio:

```{r}
reticulate::use_python(python = "C:\\Users\\jimgr\\ANACON~2\\python.exe")
reticulate::py_versions_windows()
reticulate::conda_list()

```

Set Your Conda Environment, and double check that reticulate is actually using the new conda env.

```{r}
reticulate::use_condaenv("py3.7", required = TRUE)

py_config()

```

### Python tests

Is python working?

```{python}
1 + 1

```


Sourcing an existing python script is as easy as calling `reticulate::source_python()`. For example, if you have the following Python script *flights.py*

```{python eval=FALSE}
import pandas
def read_flights(file):
  flights = pandas.read_csv(file)
  flights = flights[flights['dest'] == "ORD"]
  flights = flights[['carrier', 'dep_delay', 'arr_delay']]
  flights = flights.dropna()
  return flights
```

Then you can source the script and call the `read_flights()` function as follows:

```{r eval=FALSE}
source_python("flights.py")
flights <- read_flights("flights.csv")

```

Import numpy and pandas using the import shorthand `np` and `pd` respectively. 

- numpy: Math Calculations
- pandas: Data Wrangling

```{python}
import numpy as np
import pandas as pd
```

### Testing numpy

```{python}
np.arange(1, 10)
```

### Testing pandas

```{python}
# Make a sequence in a data frame using dict format
df = pd.DataFrame(data = {"sequence":np.arange(1,20,.01)})

# Use assign (mutate) equivalent to calculate the np.sin() of the series
df = df.assign(value=np.sin(df["sequence"]))

df
```

### Test Scikit Learn

```{python}
from sklearn.ensemble import RandomForestClassifier

clf = RandomForestClassifier(random_state=0)

X = [[ 1,  2,  3],  # 2 samples, 3 features
     [11, 12, 13]]

y = [0, 1]  # classes of each sample

clf.fit(X, y)

clf.predict(X)  # predict classes of the training data
```


```{python}
from sklearn.cluster import AffinityPropagation
from sklearn.datasets import make_blobs

# Generate sample data
centers = [[1, 1], [-1, -1], [1, -1]]
X, labels_true = make_blobs(n_samples=300, centers=centers, cluster_std=0.5,
                            random_state=0)

# Compute Affinity Propagation
af = AffinityPropagation(preference=-50).fit(X)
cluster_centers_indices = af.cluster_centers_indices_
labels = af.labels_

n_clusters_ = len(cluster_centers_indices)
```

# Human Resources Employee Clustering

## Data Ingest

```{r}
hr_data_tbl <- read_csv("data/HRDataset_v13.csv", n_max = 310) %>%
  mutate(DOB = mdy(str_c(str_sub(DOB, end = 5L),
           "/19",
           str_sub(DOB, start = 7L))),
         DateofHire = mdy(DateofHire))
  
hr_data_tbl %>% glimpse()

```

## Feature Engineering

Build better Age and Tenure Features

```{r}
minDOB<-min(hr_data_tbl$DOB)
minDateofHire<-min(hr_data_tbl$DateofHire)

hr_data_tbl <- hr_data_tbl %>%
    mutate(AgeRel    = ( DOB - minDOB)  / dyears(1)) %>%
    mutate(TenureRel = (DateofHire - minDateofHire ) / dyears(1))

hr_data_tbl %>%
    ggplot(aes(AgeRel)) +
    geom_histogram()+
    labs(title = "Relative Age Delta Distribution",
         subtitle = "Sample HR Dataset")

hr_data_tbl %>%
    ggplot(aes(TenureRel)) +
    geom_histogram() +
    labs(title = "Tenure Distribution",
         subtitle = "Sample HR Dataset")

```

## Subset & Fix Missingness

```{r}
library(DataExplorer)
```

```{r}
hr_data_tbl %>% plot_missing()
```

```{r}
selections <- c(
    "Employee_Name", 
    "Sex", "MaritalDesc", 
    "PayRate", "Department",
    "AgeRel", "TenureRel"
    )

hr_subset_tbl <- hr_data_tbl %>%
    select(one_of(selections)) %>%
    drop_na()

hr_subset_tbl %>% glimpse()
```

```{r}
hr_subset_tbl %>% plot_missing()
```

## Preprocessing (recipes)

```{r, paged.print = FALSE}
library(recipes)

rec_obj <- recipe(~ ., hr_subset_tbl) %>%
    step_rm(Employee_Name) %>%
    step_normalize(all_numeric()) %>%
    step_dummy(all_nominal(), one_hot = FALSE) %>%
    prep()
    
rec_obj
```

```{r}
hr_subset_processed_tbl <- juice(rec_obj)

hr_subset_processed_tbl %>% glimpse()
```

```{r}
hr_subset_processed_tbl %>%
    ggplot(aes(AgeRel)) +
    geom_histogram()+
    labs(title = "Relative Age Delta Distribution, Normalized",
         subtitle = "Sample HR Dataset")
```

```{r}
# Prep for Python
X              <- as.matrix(hr_subset_processed_tbl)
employee_names <- hr_subset_tbl$Employee_Name
```

# Machine Learning (Python)

## Clustering - Python
### R to Python

```{python}
r.X
```

```{python}
r.hr_subset_processed_tbl
```


```{python}
pd.Series(r.employee_names)
```

### Affinity Propagation

```{python}
# Machine Learning
from sklearn.cluster import AffinityPropagation
```

```{python}
af = AffinityPropagation().fit(r.X)
af
```

```{python}
af.cluster_centers_indices_
```


```{python}
cluster_assignments_af = af.labels_
cluster_assignments_af
```


### DBSCAN

```{python}
from sklearn.cluster import DBSCAN
```

```{python}
db = DBSCAN(min_samples=5).fit(r.X)
db
```

```{python}
cluster_assignments_db = db.labels_
cluster_assignments_db
```

## TSNE Low-Dimensional Embedding - Python

Needed to create a reduced representation of the original data in 2-D space.

```{python}
from sklearn.manifold import TSNE
```

```{python}
X_embedded = TSNE(n_components=2, random_state=123).fit_transform(r.X)

pd.DataFrame(X_embedded)
```

# Py to R

### Getting Scikit-Learn Results in RMarkdown

```{r}
# Affinity Propogation
py$cluster_assignments_af
```

```{r}
# DBSCAN
py$cluster_assignments_db
```

```{r}
X_embedded_tbl <- py$X_embedded %>% as_tibble()
X_embedded_tbl
```

# Visualizations (R)

```{r}
library(plotly)
library(tidyquant)
```

## Data Preparation

```{r}
employee_clustering_tbl <- tibble(
    Employee_Name = employee_names,
    cluster_af    = py$cluster_assignments_af,
    cluster_db    = py$cluster_assignments_db,
) %>%
    bind_cols(X_embedded_tbl) %>%
    left_join(hr_data_tbl)

employee_clustering_tbl
```


```{r}
attrition_rate_tbl <- employee_clustering_tbl %>%
    select(cluster_db, Termd) %>%
    group_by(cluster_db) %>%
    summarise(
        term_rate  = sum(Termd) / length(Termd),
        term_count = n()
    ) %>%
    arrange(desc(term_rate))

attrition_rate_tbl
```


## Attrition by Cluster Visualization

```{r}
g <- attrition_rate_tbl %>%
    mutate(cluster_db = as_factor(cluster_db) %>% fct_reorder(term_count)) %>%
    ggplot(aes(term_count, cluster_db)) +
    geom_col(aes(fill = term_rate)) +
    theme_tq() +
    labs(title = "Attrition Rate by Employee Cluster",
         fill = "Attr. Rate", x = "Attrition Count", y = "Cluster Assignment")

ggplotly(g)
```

## Cluster Network Visualization - R

```{r}
data_formatted <- employee_clustering_tbl %>%
    left_join(attrition_rate_tbl) %>%
    mutate(description = str_glue("{Employee_Name}
                                  Position = {Position}
                                  MaritalDesc = {MaritalDesc}
                                  Sex = {Sex}
                                  Race = {RaceDesc}
                                  EmpStatusID = {EmpStatusID}
                                  PayRate = {PayRate}
                                  Terminated = {Termd}
                                  Term Reason = {TermReason}
                                  
                                  Cluster Term Rate: {scales::percent(term_rate)}
                                  Cluster Term Count: {term_count}
                                  
                                  ")
    ) %>%
    select(Employee_Name:V2, description, Termd, 
           term_rate, term_count)

g <- data_formatted %>%
    
    ggplot(aes(V1, V2, color = factor(cluster_db))) +
    geom_point(aes(text = description, size = term_rate), alpha = 0.5) +
    scale_color_tq() +
    theme_tq() +
    # theme(legend.position = "none") + 
    labs(title = "Employee Cluster Assignments", color = "Cluster")
    

ggplotly(g)
```

----

### Did you find this page helpful? Consider sharing it ðŸ™Œ



