---
title: 'Building Analytics Teams: Engaging the Business'
author: Jim Gruman
date: '2020-07-17'
slug: building-analytics-teams-engaging-the-business
categories:
  - Business
tags:
  - Business
subtitle: ''
summary: ''
authors: []
lastmod: '2020-07-17T16:07:32-05:00'
featured: no
image:
  caption: 'New Holland'
  focal_point: 'Smart'
  preview_only: false
projects: []
---

Most business clients have a genuine interest in the uses of data, yet do not know how to achieve their analytics and Artificial Intelligence goals. The analyst's job is to help them understand how to navigate the journey successfully. The organization's mid-level functional managers are given latitude to immediately stop, delay, or move work forward. A handful of causes explain most of the issues with analytics in this interface. Let's look at these areas to be armed with advanced thinking about how to convince stakeholders that these roadblocks need to be overcome.

Many C-suite executives have already committed to entering the race to build artificial intelligence into the business. Often they will put the responsibility under the CIO or the CFO. I have witnessed how this is the first step towards failure. The installation of Salesforce or SAP is a well-known linear building process. Advanced analytics projects are not, and thus are not like information technology projects.

The interfaces between advanced analytics and other functional groups in the business deserves much more attention than it currently receives. Advanced analytics is focused on disruption, creativity, and innovation. Functional groups must have processes that move along structured process paths. There are far too many opportunities for misunderstandings in the handoff.

The analytics team is not a technology team. Functional teams may perceive AI as an extension of ICT, though this is a source of problems. Typically, those issues are in the perceptions of functional team leadership. The problems manifest themselves in inappropriate requests and delegation of tasks that are not a good use of the analytics team's resources. One example is the requests to build dashboards. In most cases, these Business Intelligence capabilities are embedded within functional groups.

Outside of analytics, many do not comprehend the diversity of analytical approaches required. Analytics teams are best served by having diverse skills within the team membership. Examples include natural language processing, or neural networks for images, or other wide ranging predictive algorithm specializations. 

Without a public C-suite commitment and institutional transparency, the analytics and AI team is just overhead. You cannot club your way to success as a caveman. You are not the only game in town. Executives have many teams reporting up through organizational structures. Each department has numerous initiatives underway of their own. Just because you are living and breathing the portfolio of analytics projects does not mean that any senior management have any more than a cursory understanding.

**Call to action**:In this post we will examine examples of roadblocks, keeping in mind that we are describing each so that you can formulate your own views on how you, your analytics team, and the broader organization can surmount each obstacle. Let's lay out the case for how we can engage even the most intractable parts of organizations to move them in a direction where we can build systems that will drive positive change.

{{< figure src="./anisur-rahman-K2b7UDed6uQ-unsplash.jpg" title="Anisur Rahman" lightbox="true" >}}

## Overcoming Roadblocks to Analytics Adoption

Tom Davenport and his co-authors offered the following observation: 

>"[More than a decade after the concept of big data became part of the lexicon, only a minority of companies have become insight-driven organizations...](https://www2.deloitte.com/us/en/insights/topics/analytics/insight-driven-organization.html)"

In using Davenport's quote about the passing of a decade, I want to ensure that we understand that analytical approaches have been around for a significant period of time—certainly longer than the decade we have been talking about "big data" for. When you think about it, analytics has been with us for centuries, and only in the past decade has there been the widespread interest in serious utilization to improve business operations, government, society, and our world as a whole. 

We need to ask: why is this so? We have, within our reach, large amounts of relatively easy-to-access data and algorithms that are invoked through user interfaces that guide even the most novice of users to a reasonably accurate path. This is coupled with more than ample network connectivity/bandwidth, and compute cycles are, for all intents and purposes, infinite. So, why is it that we are not doing more with data and analytics? What are the limiting factors? What can we do to lessen the impact of, or completely eliminate, those impinging factors on our efforts to drive change through data and analytics? Davenport and his co-authors go on to assert that:

> [The amount of data available to organizations every day continues to proliferate at a staggering volume. But technologies such as analytics and artificial intelligence have the potential to help businesses make better use of these massive volumes of data. In an age of collaboration between humans and machines -- what is, as Tom and his coathors call, "the Age of With"?](https://www2.deloitte.com/us/en/insights/topics/analytics/insight-driven-organization.html)

In his [new book](https://www.amazon.com/gp/product/B08C76CV5Y/ref=dbs_a_def_rwt_bibl_vppi_i0), John Thompson discusses how the future of advanced analytics and AI as being one where AI will be used in conjunction with human judgment. In Judith Hurwitz and Henry Morris' new book, [*Augmented Intelligence*](https://www.amazon.com/dp/0367184893/), they outline how fully integrated hybrid human and AI systems will permeate our business operations, social media, and other services that we utilize daily. 

As an example, a team at Dell Software created a system to predict which patients had a higher probability of developing sepsis after surgery. Post-surgical complications are a serious occurrence. In fact, they are the most common reason for unplanned readmissions to the hospital in the United States. The advanced analytics team there worked with the University of Iowa Hospitals and Clinics to develop an analytics system that predicted which patients were at greater risk of suffering an infection from a surgical wound. The system used a variety of data, including details of the surgery itself, such as the patient's vital signs, and information from the person's medical records—whether, for example, he or she has diabetes or hypertension. By analyzing an ensemble of data, the system could predict the likelihood of infection while the patient was still on the operating table. For patients who were at higher risk, doctors could then use a different technique of closing or treating the wound, or prescribe a more effective regimen of post-surgery medication. The results of this sophisticated analytic environment have been impressive, [with the rate of infections for patients following colon surgery plummeting by more than 75 percent over a three-year period](https://www.tibco.com/customers/university-iowa-hospitals-and-clinics). This is an example of an augmented intelligence-based approach to surgery. 

UofI did not and does not talk about this as a human surgical team augmented by a robot, though some people have described the system in those terms. We see it as the augmentation of the intelligence of the surgical team with an AI based system that provides guidance in a non-intrusive, supportive manner in a timeframe that can improve surgical outcomes for the surgical team, the hospital, and most importantly, the patients. 

**Call to action**: Always empower the domain experts with augmented decision support tools that help make what they do for the business, better.

On a positive note, all the necessary building blocks are in place and generally available to all corporations and a significant portion of the general population to leverage advanced analytics: hardware, software, high-speed networks, a proliferation of detailed real-time data, powerful data management, far-reaching data integration, an increasing level of digital literacy skills, and a growing awareness of the need for and value of advanced analytics and AI.

{{< figure src="./pratham-gupta-DksFIwoPLAA-unsplash.jpg" title="Pratham Gupta" lightbox="true" >}}

## Organizational culture

Currently, there is an intense wave of interest in both the positive and negative impacts of Artificial Intelligence. Though there were waves of interest in computing, information technology, and even the internet in the past, the previous episodes did not offer the potential of practical results to so many organizations. We certainly did not have as many success stories to convince people that analytics can make a difference in their lives, work, school, government, or communities. Interest is required, but interest is not enough to drive action. We need to enter discussions with stakeholders under the assumption that the advanced analytics systems being developed will be implemented and will change the way that operations are executed. It seems odd for me to write this and probably strange for you to read it. You would never enter into a major technology project or process re-engineering effort thinking that the end users may or may not use the results of the project; the organization is committing to whatever project it is, and therefore it is assumed that the end users will adopt the results without question. That is not always the case with analytics projects. Often, the advanced analytics and AI team approaches a problem, diagnoses an issue, and shows the end users the results and a path forward to eliminate a problem, improve an operation, or find some other possible improvement in the management of the functional department.

I would expect that if managers were shown a better way, they would have, of their own volition, adopt the improvement and change the systems to incorporate the data-driven insights. Typically, that is not the case. 

One way to improve this situation is to extend the projects being executed by the advanced analytics team to be included in organizational change management processes. The advanced analytics team does not need to run them—the processes can be run by project management teams—but the advanced analytics team needs to consult on the changes to ensure that processes do change and that the organization delivers the benefit. In addition to the issue of complexity that we just discussed, there can be political or communication issues at play. Political issues come generally from turf battles or not-invented-here aspects of the organization that analytics leadership must address directly. Communications issues can come from the analytics team not clearly explaining the relative value delivered by the change, or from perhaps not promoting it to the right audience. 

For example, projects that result in potential improvements by reducing the labor required to complete a task can turn to confusion when the functional leader doesn't implement the change. The functional leader may not make the change due to a perception on their part that doing so would adversely impact their personal career progression. Analytics leaders may need to walk the functional manager through the change and expand their thinking into what new possibilities for value creation emerge as you free up their team for more creative pursuits. 

Organizational culture is a powerful force, and that force, in the majority of organizations around the world, tends toward stasis and even active resistance to deep structural change. While many of us think that if a good idea is developed, the organization will adopt it, that is not true in most cases. Again, we in analytics are different: we like complexity, we like change, and we do not only like change, we seek to change things in a proactive manner. Most people do not have that mental orientation or personal constitution; most middle managers seek to actively avoid change. While it may seem, on the surface, that organizations are in a constant state of change, corporate cultures and the majority of managers and executives work proactively against change. It is true that superficial change is nearly constant. An example is moving from a vertical industry focus to a horizontal process. Nothing changes except the superficial organizational structure. The culture doesn't change, the majority of processes do not change, and the pricing structure remains essentially unchanged. 

Analytics leaders and analytics teams look beyond the superficial. They look at the data, the operations, the efficiency, and the effectiveness. Analytics teams produce fact-based illustrations of why organizations, team structures, processes, prices, and more need to change for an organization to improve. While superficial change is abundant, deep structural meaningful change is rare. So, we must recognize that we have a mismatch in modalities. That is fine—we just need to realize that where the analytics team seeks change, middle managers see danger. The analytics team needs to design a change process as part of every project and the analytics team and the project management team needs to help the functional teams to move through the prescribed change.

There exist executives who believe that all data and analytics projects can be outsourced. It is possible, though I have not yet seen this type of effort deliver strategic impact, but that does not mean that it cannot yet happen. One of the challenges of outsourcing anything -- whether AI or a new vehicle design -- is that you need to know what you want to have in the end before you start. How can you expect an external vendor to deliver exactly what you want, when you want it, at the expected cost when you cannot write a statement of work? You would be surprised how many teams have little or no idea of what they want to do. This is a particularly acute problem in analytics currently. Most executives have no basis for discerning the possible from the impossible.

**Call to action**: Engaging the data science team itself to drive change may be a waste of talent, time, and money. Many enterprises have a change management group that is chartered specifically with driving the operational changes. The change management team is, in all likelihood, not part of the advanced analytics and AI team, but they are the team or group that the analytics team can hand off change management processes to. Most people find change hard. The processes that the advanced analytics team changes with data and analytics might represent especially hard changes for an organization. The analytics team needs to consider the reticence of the organization and plan for how to overcome the tendency to the status quo.

{{< figure src="./ian-_WRwaR7_fG4-unsplash.jpg" title="" lightbox="true" >}}

## Data or Algorithms - The Knee of the Curve

We all have reached, and passed, an inflection point in our engagement with analytics. We all have heard the arguments that algorithms are the seat or source of competitive advantage. We all have been told that if you are smart, innovative, and own your own algorithm(s) or approach, then you have mastery over all your competitors and the road to success is nearly assured. Also, we all have heard, sometimes from the same experts who asserted the previous point, that the pathway to all success in analytics is through the ownership, control, management, and proactive use of data—large amounts of typically fast-moving data. 

Why discuss data and algorithms here, as part of a post on organizational engagement? Expect to be put in the position to refute the argument from functional managers, even numerous times. Functional managers will advocate for investments in data or algorithms, but rarely both. The analytics leader needs to be cognizant that investing in data at the expense of algorithms or vice versa will lead to less-than-optimal outcomes. The analytics team and the organization need to focus on both simultaneously. People are continually invoking velocity as a way to create urgency in why investors need to hand over their money, or why an enthusiastic advocate needs to build a team and start today: because the competitors are already moving and each moment that you do not move, you are losing to the fictitious "them." As with most arguments or discussions, there are kernels of truth in each of these positions; they are true, in part. The inflection point has illustrated to us that we need algorithms and data preparation techniques, but that owning them outright is nearly impossible. Math is infinite and the ways to reach solutions to problems are manifold. If you go to all the time to protect a methodology or a math function, someone else will reach the same point of effectiveness, or probably exceed it, through a different approach that you have not secured through legal means. Your best path to success in this area is rapid innovation. Given the limited nature of the ability to protect methods, constant innovation coupled with security is the best answer when thinking about the math side of the ecosystem.

Of course, as with all situations or positions, there are special cases. In our discussion, I am assuming that you do not work for or control a global technology company like IBM, Microsoft, Alibaba, or Hitachi. Those companies have made multibillion-dollar commitments to develop, maintain, and extend patent creation engines, which are a source of competitive advantage. If you work for a company in this class, then you can protect your intellectual property through legal means, but for this post, we are not assuming that you work in one of these firms. 

After passing the inflection point we know that we need data. But for data to be truly valuable to us in our efforts, data must be free of the common problems that we have faced in the past. Let's talk, very briefly, about some of the problems with data encountered frequently in analytics. Four of the most foundational problems are: 

- **Synthetic data**:  Creating test data in the volumes needed to enable the valid testing of analytical applications is challenging to the point of being nearly impossible. Generating the data needed from a small sample set of data is typically not representative of the real world. It seems so very simple on the face of it, but it is not. Often it is easier to obtain large volumes of test data from external sources, but if the organization is seeking to test a unique application with data specific to use cases that are limited to the organization only, the cost and effort involved in obtaining truly representative test data is not to be underestimated. 
- **Bias**: Bias is baked into the data that we create and the real-world data that we want to use. Taking a small amount of limited data from limited datasets of customers, partners, consumers, technicians, and/or other groups institutionalizes the bias. Patterns that would occur in natural systems are difficult to create in, and generally do not exist in, synthetic or limited sets of data. How do we solve this in a way that is fair but realistic? 
- **Limited breadth**: Most people have been inculcated with the belief that a large amount of uniform data is the best way forward in analytics; that is not true. Diversity of data produces the best results. You need internal and external data integrated together to understand the multiplicity of phenomena that occur in the real world. In the real world, almost nothing occurs in an isolated vacuum. Relationships in one area impact the results in another area. While it is impractical to think, at least in the short term, of modeling the entire world, we can model smaller, related systems and analyze those ecosystems to understand how interactions occur and how they impact the operations we seek to optimize. 
- **Volume and velocity of data**: In the past, we had data, but not enough of it and certainly not the variety of data sources needed. We did not have the tools, technologies or the skills to integrate data at scale, and we certainly did not have access to real time data or the ability to get data fast enough to act upon within a timeframe to make a valuable response to the relevant people and processes. An entire book could be written about these limitations, and other people have done so successfully. These problems can and still do inflict limitations on analytics projects, but they do not need to. We are well aware of these problems and we can avoid them or solve them up front.

To sum up these key points: 
- **Algorithms** have been with us in a recognizable form for centuries 
- **Data** has been generated since the beginning of human existence 
- **Compute power** is now ubiquitous and cheap 

Never before in history have we had the combination of math, volumes of diverse and readily accessible data and the power to compute it that we now have at our finger-tips. When we have all three of these fundamental elements working together in real time and on a continuous basis, we can produce valid scalable results in real time that can be used to monitor and manage almost any process in an automated fashion. 

**Call to action**: The main point is that it is not data *or* algorithms, it is data *and* algorithms. They each reinforce the value of the other and amplify their impacts in an evolving and dynamic manner. Don't let people simplify the equation or need for investment and focus to one or the other—both are required for success and successful change.

{{< figure src="./andreas-klassen-gZB-i-dA6ns-unsplash.jpg" title="Andreas Klassen" lightbox="true" >}}

## A Managerial Mindset

I completed my undergraduate degree in Mechanical Engineering in 1993. Before finishing, I took advantage of a rare opportunity then to work with vehicle dynamics simulations, first in FORTRAN on VMS and then in C. We openly wondered, "Is there a future in this?" It seems a silly observation, but think of it: there are still a significant number of managers who graduated from their undergraduate programs in the 1980s and 1990s. Many of those people have a cursory understanding of computers and programming, and even less of an understanding of data and analytics. Generally, people do not enthusiastically embrace what they do not understand. You won't find many, if any, of that generation of managers who will freely admit that they do not fully understand basic computing technology. Ask them how a computer transfers data from disk to memory to a processing unit and I am quite confident that a blank stare will be the result in the majority of instances. If this is a mystery to them, I am certain that there is an infinitesimally small percentage of that managerial population who understand basic descriptive statistics, let alone advanced analytics and AI.

> […a recent Deloitte survey, Analytics and AI-driven enterprises thrive in the Age of With, The culture catalyst, of U.S. executives that found that only 10% of companies are competing on their analytical insights, and that the most popular tool for analyzing data — used by 62% of companies responding to the survey — is the spreadsheet?](https://www.thelowdownblog.com/2020/02/what-separates-analytical-leaders-from.html) 

Given that this is a reality for the next decade or more, what do we do about it? Patience and clear communication are recommended for a start. Normally, I would have said concise communication, but in this case, a significant amount of talking, writing, coercing, and convincing are needed. 

Several years ago we conducted market research related to an all-new CVT transmission for 4WD agricultural tractors. The rationale was to quantify the impacts of the features across customer segments and machine configurations. We needed to be able to generalize the results in the future as market forecasts, so uncovering the root causes of customer preferences was crucial. The functional territory marketing group worked together with product development and analytics in preparation, as the week-long event required tillable land, fuel, implements, shuttle vans, hotel, and countless other details. For the most part, the performance characteristics in fuel consumption and speed were already known. The missing knowledge was in quantifying the user interfaces, comfort, experiences, and price sensitivity. As is the case with most market research, controlling for biases was difficult.

A stratified list of customers was identified, contacted, and incentivized to fly for one day to Arizona to participate in field demonstrations of equipment that they were familiar with in tasks they were familiar with, and the same again with CVT tractor prototypes. A script was prepared on tablet computers for interviewers to ride along with the customer and to record their reactions. 

![MAC](https://cals-mac.arizona.edu/sites/cals-bigmac/files/macaerialmap.jpg)

The customer reaction statements were parsed and analyzed for sentiments, along with their prior demographics. A decision report was prepared within the team, edited, and then shortened into an executive summary for management. Oddly, when presented it was as if the functional territory marketing group had never seen the complete analysis before. The analytics team was flabbergasted at the lack of  ownership of the whole market research process. Even so, the meeting with the executives was a success. The executives were happy to see that data and analytics were being used. 

How could the analytics team have been more effective in encouraging greater adoption of precise statistical methods and in knowledge transfer? It was surprising to the analytics team how little ownership that the functional team had. It was clear that the territory marketing team understood the value being delivered. Part of the issue that was uncovered was that the management of the marketing team had been managing the business in the same manner for over 30 years. 

**Call to action**: Do not underestimate the lack of awareness in existing middle managers of the need for changes in processes, training, job content, and performance management to fully utilize data and analytics.

{{< figure src="./brandon-mowinkel-yctiRnbY7w4-unsplash.jpg" title="Brandon Mowinkel" lightbox="true" >}}

## The Skills Gap

Another real and present reason for the lack of progress in leveraging analytics is the talent gap. In the popular press the conversation is typically discussed in terms of the lack of students in STEM (Science, Technology, Engineering, and Math). Though there is definitely an issue with the lack of qualified students here, the problem for advanced analytics teams is even more acute. Hiring managers cannot find enough talented people to build, manage, and maintain an evolving ecosystem across all of the domains that want to build out their analytics capabilities. Tom Davenport and his co-authors also explored organizational gating factors in the adoption of analytics:

> [Our survey results clearly show that analytical competitors represent a minority of businesses today, despite the number of years technologies like big data and analytics have been readily available. Becoming an organization that's driven by data and analytics is not the result of any single factor; it is multidimensional. For organizations to fully leverage the insights they derive and embed them into decisions and actions, a combination of three drivers is required: data and tools, talent, and culture.](https://sloanreview.mit.edu/article/what-separates-analytical-leaders-from-laggards/) 

When encountering multidimensional challenges, timing is important. Each portion of the ecosystem—talent, tools, culture, and more—can be mutually reinforcing or destructive. If you hire talent and do not have tools, the teams will be restless and question whether management is committed to analytics. If you have tools and talent, but no widespread support for using data and analytics, your results will suffer. It is important to build support with management, invest in tools, engage with a broad community to build grassroots support, use data and analytics, and then finally hire more than a handful of talented analytics professionals to begin working on projects with stakeholders and subject matter experts. Davenport and his co-authors exhort us to work hard to enlist executive sponsors, which, as we know, is important:

> [Aim high for analytics champions. Executive sponsorship is vital to this level of organizational change, and the best champion sits in the corner office. According to the survey, the CEO is the lead champion of analytics in 29% of companies surveyed, and these companies are 77% more likely to have significantly exceeded their business goals. They are also 59% more likely to derive actionable insights from the analytics they are tracking. Companies should hire or promote leaders with a strong orientation toward analytics-based strategy and competition.](https://sloanreview.mit.edu/article/what-separates-analytical-leaders-from-laggards/)

Beyond executive sponsorship, we need middle managers to show overt support for data and analytics projects. We need to:

> [Encourage leaders to model examples. In meetings, for example, leaders should demonstrate the importance of analytics by asking for data points to back up business decisions. There is a major opportunity for companies to provide more education and improve the user experience if they want every employee to use insights as part of their work.](https://sloanreview.mit.edu/article/what-separates-analytical-leaders-from-laggards/) 

> [To really succeed with analytics, a company will need to acquaint a wide variety of employees with at least some aspects of analytics. Managers and business analysts are increasingly being called on to conduct data-driven experiments, interpret data, and create innovative data-based products and services. Many companies have concluded that their employees require additional skills to thrive in a more analytical environment. One survey found that more than 63 percent of respondents said their employees need to develop new skills to translate big data analytics into insights and business value. Bob McDonald, at one point CEO of Procter & Gamble and then head of the U.S. Veterans Administration, said about the topic of analytics (and business intelligence more broadly) within P&G: We see business intelligence as a key way to drive innovation, fueled by productivity, in everything we do. To do this, we must move business intelligence from the periphery of operations to the center of how business gets done. With regard to the people who would do the analysis, McDonald stated: I gather there are still some MBAs who believe that all the data work will be done for them by subordinates. That won't fly at P&G. It's every manager's job here to understand the nature of statistical forecasting and Monte Carlo simulation. You have to train them in the technology and techniques, but you also have to train them in the transformation of their behavior. Of course, all senior executives are not as aggressive as McDonald in their goals for well-trained analytical amateurs. But in even moderately sophisticated companies with analytics, there will be some expectations for analytical skills among amateurs of various types.](https://www.amazon.com/dp/1119483212)

**Call to action**: Analytics is a skill set and core competency that our entire workforce needs to  master at some rudimentary level. As stated above, we need all employees to be adept and competent in analytics. One of our long-term goals should be that there are no advanced analytics teams, that everyone becomes an analytics practitioner. One of the more reliable indicators of whether someone leans towards the more open-minded end of the spectrum is whether they hold a view that lifelong learning is a key to achieving relevance to the enterprise. Do employees support their teams learning on the job? Do they send their employees to other business units to immerse themselves in operations? Do they ask questions of others and take a genuine interest in learning?

Make it widely known that principal and senior analysts are expected to manage a Special Interest Group in a Community of Practice. The Community of Practice should comprise a few hundred members. They will set the cadence of learning sessions and ensure that the events remain interesting and an engaging forum for the relevant interests of the members for the state of the art in machine learning, geospatial topics, etc.

And if growth in data and statistical skill sets is really is one of our long-term goals, then we should be working with our local elementary schools, middle schools, high schools, colleges, and universities to ensure that they are all teaching data literacy and analytical competence.

{{< figure src="./jess-bailey-l3N9Q27zULw-unsplash.jpg" title="Jess Bailey" lightbox="true" >}}

## Linear and non-linear thinking

Developing analytical applications is a creative endeavor. The process is characterized by fits and starts, dead ends, sparks of brilliance, and eureka moments. Who would not want that in their daily jobs? It turns out, lots of people would rather never have to do any of it. They are linear thinkers. 

Linear thinkers are everywhere. You may be one of them. I am not. No matter—we can all work together. Linear thinkers tend to see things in black and white. They want concrete defined dates. They see the rules as immutable. Again, no worries, we can all get along, if we are willing to listen to each other. 

Working with linear thinkers—and you will have to, because they are the majority of people who are successful in business today—is not as hard as it sounds. You simply need to spend much more time setting expectations for and with them. Think about every date that you can possibly define in a timeline of a project and multiply that by a factor, and you will understand the level of detail that the linear thinkers will want to have. They have a seemingly endless need for minute detail. Much of the requested detail is never needed, but you will need to calm them down, and a mass of details seems to do the trick. This is one of the reasons why if you are taking a new role in a company and they announce that the advanced analytics and AI team will report into the Information Technology team, you have an uphill battle on your hands. Unless the manager of those functions and your new manager are remarkable, you will have to contend with the modality mismatch. It is not a fatal flaw, but tiring to deal with on a routine basis. To be fair, linear thinkers are typically experts in an area—areas such as production planning or large system implementations. Rarely are they experts in data and analytics. 

Well-adjusted linear thinkers know that they are experts and they may still be inquisitive about data and analytics. The most obnoxious and self-assured linear thinkers are smugly convinced that they know everything. The latter are the most difficult people to work with, and, in the end, it may not be possible to work with them; they are exhausting. You will learn through experience that just because a person is a professional, that does not mean that they have a very wide field of vision or curiosity. 

**Call to action**: Don't expect linear thinkers to change or open their viewpoints. If you are a non-linear thinker, you can see ways to approaches that linear thinkers cannot see and cannot even conceive of as being possible or practical. They are like fish—water, what water? They are so enveloped by their view of reality, they cannot even see it. Perhaps you can help them by leveraging their single-minded focus and disciplined thinking. Help them find the new groove and they can accelerate that line through their complete focus to not get sidetracked. Set them in flight to come back with new ideas on a periodic basis that they can digest.

{{< figure src="./stellrweb-djb1whucfBY-unsplash.jpg" title="Stellr Web" lightbox="true" >}}

## Do you Really Need a Budget?

Budgets are many things to many people. For most, they are a way to keep score. Who has a bigger budget? How can you take money from someone else's budget? However, what if you didn't need a budget? In an advanced analytics and AI team, you really do not need a discretionary budget. Of course, you need money to pay for salaries, incentive compensation, desks, office space, travel and entertainment, and setting up your team with the appropriate technologies, but after you have the team hired, the infrastructure built, and the software installed, do you need a big or any additional budget to be effective and to deliver results? 

Trust me, you don't. 

Budgets are always tight. Actually, I am having a hard time recalling where budgets were freewheeling and we were let free to spend whatever we wanted. The point is that budgets are always controlled. Since the advanced analytics and AI market is mature, evolved, and wide open from a technology perspective, and there are so many options for powerful multifaceted analytical platforms, most teams really do not need to buy software from IBM or SAS. Your team can be very effective using open source software for a substantial portion of your work. The R and Python environments offer powerful, valuable, and easy-to-access tools. Open source visualization tools like ggplot2 are easy to access and use. Of course, you will need databases, interactive development environments, deployment-grade software, and a number of other tools to enable and empower your team, but most of those tools have already be licensed when working in an established enterprise-class business. Someone somewhere in the company needs these tools too, and the other teams were probably in the organization before your team arrived. You can leverage the master services agreements that the firm already has and piggyback off the departmental licensing deals to get started. Once you have found where the tools you need are licensed and you have contributed your portion to pay for the licenses, there really isn't much for you to spend money on. It will seem strange to your colleagues, and if you have never managed an advanced analytics team, this lack of a need to jockey for budget funds may seem strange to you too. In most technology projects, people think that analytics projects are technology projects. People think that you need to buy hardware, software, professional services, management consulting services, and more, and in some cases, you need to—but in the majority of analytics projects, if you have hired the right team members, you will not need to spend any additional funds.

**Call to action**: Budgets are a roadblock to success. The budgeting process is divisive. Budgets can take a great deal of your time, especially when you are politicking to gain more money or to take money from someone else. Budgets can be contentious and they can be a problem. Or, budgets could be no big deal; that is how I choose to deal with them. Set up your team, hire the right people, and put the budgeting cycle on autopilot. This approach saves you time, money, and anguish. Who doesn't like that? No one.

{{< figure src="./clay-banks-1Uj0HmqQFGk-unsplash.jpg" title="Clay Banks" lightbox="true" >}}

## Not big data but Lots of Small Data

If you are fortunate enough to work with experienced professionals that know how to acquire, integrate, and analyze a wide range of related but disparate datasets, they really do not worry about bringing together a couple of databases for analytics. They see this activity as quite natural. Integrating data together is an incredibly valuable core activity that provides insights and is the framework for new tools. 

Years ago, we would only integrate datasets that were obviously related. We would integrate shipments information from the client company systems with the consumption data from grocery stores. Consumption data or scanner data from Nielsen would be integrated with survey data from Simmons on what consumers purchased and how they used a client's products and products from their competitors. No real stretch there; we were looking for a complete picture from the supply of raw materials, through production, to shipment and storage, to retail stocking and sales, to stocking in a pantry, to the ultimate use. That was easy and it was clear what we were looking for. 

Today we have moved well beyond the obvious. To be clear, we still do the obvious for obvious reasons, but we now are looking at integrating far-flung data sources. We are searching for non-intuitive connections. We are looking for sources of competitive advantage that have not been thought of yet. To be clear, this point is critical. There will be functional managers and executives who will argue for using limited data sources, possibly in large volumes, to analyze the phenomena that you are seeking to understand. They will do this for a number of reasons, which may include cost reduction, a simplistic view of the problem statement or area, or other motivations. What matters most, and the reason that we emphasize this point, is that you as the analytics leader need to advocate for the use of a wide range of disparate internal and external data to develop solutions that are differentiated from the competition and that provide a lasting basis for competitive advantage. One of the talents and traits that you want in your advanced analytics team members is creativity in thinking about data and the wide range of internal and external data sources that you can access, integrate, and use. If your team does not have at least one person who is passionate and curious about how to leverage data, your team will unlikely be able to reach their potential.

**Call to action**: Successful analytics and AI teams routinely integrate data from a significant number of disparate sources. Consider survey data, sales data, machine telematics, website visits, complaints, compliments, production yields, safety data, quality data, price and volume data, forecasts and actuals, financial data, supply chain data, warranty claims, test results, reject rates, and more. Also, successful analytics teams integrate a vast array of data from external commercial suppliers; local, state, and federal government sources like USDA, USGS, and NOAA; academic sources from research studies; and more. One aspect to be aware of is that collecting these sources of data will span a wide range of departments in the company. 

Why should you care about this fact? The more people who are involved in the process, the more explaining, teaching and approving that is required. The more departments and managers that are involved, the bigger the need them to budget for the acquisition of expensive data sources from commercial suppliers. Government and academic sources involve much less overhead and can generally be obtained and used without many, if any, restrictions. An operational consideration, and one that analytics teams continually overlook, is that if you are utilizing a dataset once, it is highly likely that you and your team will use it multiple times. More than once in a single analytical application on a refresh basis and possibly for multiple analytical applications. In nearly every case, it makes sense to build the data acquisition, transfer, loading, and integration logic in a modular reusable manner. Building the software, scripts, and utilities in may take a little longer, but you will have an asset that the team can reuse for years. It is worth the incremental time and effort.

{{< figure src="./lars-bo-nielsen-YLqW4jNrKiI-unsplash.jpg" title="Lars Bo Nielsen" lightbox="true" >}}

## Introductory projects

It is often unclear if the sponsoring stakeholders & subject matter experts are fully committed to the project that you are chartered to undertake. Of course, they will say that they want to engage, and they will assign people to support the efforts of the advanced analytics and AI team, but they may not even know the implications of engaging in an analytics project. It is almost certainly the case that they do not know the full implications of engaging in the project and the results that will be shown. 

**Call to action**: I strongly suggest that the first project you do with a new functional area, a new manager, or an executive that you do not have an existing relationship with should be a short project. 

Not short as in small in ambition or scope—you can definitely take on a significant issue or challenge for the company or cause—but you should break down the initial stage of the project into a piece of work that can be completed with compelling results in 2 to 4 months. End users cannot see or envision the results that they will be expected to work with, and they are even less capable of understanding the cascade of changes that will need to be enacted to realize the full benefits of a data and analytics-based approach. No doubt stakeholders will be impressed that your team are committing to deliver results so quickly. They will have no knowledge that you are doing this for your benefit more than theirs. What happens in many cases is that you and your team will illustrate an interesting insight or find a result that is not intuitive. You can use this finding to open the discussion regarding planning the phase of the work, where the predictive models become part of the newly re-engineered production process. Most managers will not act surprised, but they will be and may resist implementing the changes. You need to gently persist in the belief that the data, insights, and analyses are leading to an improvement in pricing, operations, marketing, or whatever functional business unit you are analyzing. The organization did not invest in an analytics team to have results be ignored. You may have numerous conversations and you may have to escalate the process to your management, but if the results are not used to benefit the company, you do not want to be the person who did not push for full value realization. I am not a fan of this kind of maneuvering, but in this case it is unavoidable.

{{< figure src="./neonbrand-JW6r_0CPYec-unsplash.jpg" title="" lightbox="true" >}}

## Value realization

The [Institute for Operation Research and Management Science](https://www.informs.org/) meets annually and publishes stories that record a wide range of reactions at organizations as their own advanced analytics teams deliver positive change. For example, the manager of an advanced analytics team at one of the leading manufacturers of athletic clothing described a situation where the analytics team worked on projects for all functions of the company, but most were focused on marketing and sales. If the project findings supported what the sales and marketing leader believed and had planned to do, the results were embraced and used in building the case or executing the plan. If the analytical findings indicated that there was a better way to execute the plan, then the results were ignored, and the plan was executed as the sales and marketing leader intended. This happens everywhere. 

The question is, what do you do? 

**Call to action**: The projects that the advanced analytics team undertakes need to have visibility to your management team, to the management team of the functional area, and to the executive leadership team. This institutional transparency is best achieved through written, verbal, and personal communication. Visibility to the management of the analytics team and to the functional team is best achieved through routine status reports and personal meetings. Visibility to the company is best achieved through company bulletins, newsletters, company app updates, social media channels, and other communication vehicles. 

The director of analytics should not more than 2 to 3 levels away from the executive leadership, and therefore your updates to your management should filter up the executive leadership team. With visibility comes accountability and responsibility. Given that the analytics team has delivered positive messages and solid analytical insights, when you are asked when functional change is to be implemented and value realized, you can point to the level of collaboration with the functional team and their management. This post has described how certain managers have little appreciation for or understanding of technology, data and analytics, and we also have talked about how people tend to try to ignore discussion where they are uncomfortable. This is the perfect storm of all of those factors. You cannot and should not be party to this. The projects that you and your team are undertaking should all conclude with a phase where organizational change is undertaken or where analytical applications or models are put into production usage. 

Good ideas have a long shelf life, and most businesses run on repeating cycles. You do need to collaborate with the functional team to help them understand how to leverage the insights to realize the full value of the findings. In most organizations, it will be the responsibility of the functional team and a change management team to implement the process and operational changes, but you need to have your team ready to consult on the actual changes. It may be the case that the functional team is too busy to make the change when the insights are produced. The functional team may need to consider their plan for the optimal time to implement the suggested changes. The timing of the change is the responsibility of the functional team and their management. Your analytics team can move on to other projects, and when the question comes to you as to why the results have not yet been implemented, you can point to the functional team and their timing and process. 

In most cases, there is no shortage of project work for the analytics team to undertake. Part of your role, and that of your team, is to set the functional teams up for success and be ready to collaborate through the value realization process. You cannot make them leverage the insights that have been found, but you can be ready to explain to your management, the managers of the functional areas, and the executive leadership your role in the process. On the other hand, there are organizations and functional groups that are eager to accept that insights have been found and new ways of executing processes are possible and probable. The analytics team collaborates with the functional team and the organizational change management team to implement the changes needed in operational processes to take advantage of the modes and insights developed. 

With each successful project comes a growing set of analytical applications and models that need to be maintained, extended, and refreshed. Your team will need to keep in mind that all analytical applications should be built in a way that means the functional teams can accept responsibility for interacting with and using the analytical applications in their regular operations. If the advanced analytics team needs to run every application, the bandwidth and productivity of your team will grind to a halt quickly.

{{< figure src="./cristofer-jeschke-YK8Mvocj6yE-unsplash.jpg" title="Cristofer Jeschke" lightbox="true" >}}

## Discovery

When you are building an analytics team in an organization with little experience with data and analytics, the expectation from many people, including executive management, will be that the analytics team will discover new insights about the business. This is not unreasonable.

Given the fact that you and your analytics team will be given the chance to look across much, if not all, of the organization, you will have access to nearly all the data available internally and externally, and have the goodwill and collaboration of a substantial number of sponsors and subject matter experts, as well as external partners, to deliver new insights.

This type of discovery-oriented analytical work is typically driven by the art of the possible. You can plan projects, but discoveries rarely show up when planned. Your team may find interesting insights a few days into the work or it may take a year or more to find an insight that is truly game changing for the business.

While most people think that analytics work is the straightforward application of math to data, it is not that simple. You and your team do need data, and need to have a mastery of analytical techniques, but analytics projects have more of a creative element than most people realize. Many of the most talented analytics professionals possess a unique combination of analytical and creative skills. This fact is part of the reason why managing an analytics team is not the same as managing a technology team. There is a need for data exploration, hypothesizing, testing, and interrogation of ideas, concepts, dead ends, and surprising discoveries.

Often the ideas crafted by the analytics team as part of the concept generation phase of launching a project will be dismissed by the functional business teams. These may very well be the ideas that produce the most impact models and applications later. 

Linear thinkers will want to know the date and time when the eureka moment will occur. The process does not work that way. Some theories pan out, others lead in completely new directions, and others are spot on and take the team forward to new levels of understanding and improved performance.

**Call to action**:  during the early stages of analytics process, it is best to not try to limit the scope of investigation too narrowly. It can dampen creativity and lead to suboptimal results. Iterative cycles, not to mention trial and error combined with a bit of patience, is required.

The world changes continuously. The representation of the world as viewed from an analytical model is derived from observations in the data. As the world, people, market environment, and operations change, the data also changes. Models that work built with data from previous periods need to be refreshed and updated. 

If the organization does not have a process for navigating failures, I suggest that the team establish one and share it with management. It can be refreshing. 

There is a wide spectrum of appropriate windows for updating models. Some continuously, and others annually. Each case is unique and needs to be discussed and managed with the business. "Model drift" a difficult concept for some executives and functional managers to grasp. It is also a misnomer, in that the model that was scored has been static, and the training data has changed. Deploying model updates into production is a loosely coupled interface that must be managed through a cycle.

## Summary

The aspirational goal we all hear from all managers is that they want to have a data-driven, analytically tuned operation. 

Middle managers get bad-mouthed regularly. I am sure that as you read this, some of you may feel that I was taking unfair aim at our middle management compatriots. I meant no harm or disrespect. Again, this post is about understanding the roadblocks that teams encounter. 

Think through them ahead of time and consider your team, the organization you are working for or consulting with, and the best method possible for explaining the challenge, the solutions, and the benefits of moving past the current roadblock to your collaborators.

**Remember, you are the expert and they are the novices.**

It is your role and responsibility to teach them and communicate with them and convince them that they should come on this journey with you and your team. At first, this may seem to be a waste of your time, but trust me, it is not. You need them and they need you, even if they do not know it yet. Be patient and describe the challenge, solution, and benefit in as many ways as required for them to buy in and join the journey. 

The burden is on you as the expert to bring the stakeholders along on the journey. It is obvious to you, but not to them. The pitch has to be made. 

At the top of the list, empower domain experts with augmented decision support tools that help make what they do, better. The building blocks are there.

Drive organizational change through a change management group that is chartered with driving the operational changes required to realize the full value of the intelligence generated. The processes that the advanced analytics team changes might represent especially hard changes for an organization. 

It is not data *or* algorithms, it is data *and* algorithms. They each reinforce the value of the other and amplify their impacts in an evolving and dynamic manner. Don't let people simplify the equation or need for investment and focus to one or the other—both are required for success and successful change.

Do not underestimate the lack of awareness in existing middle managers of the need for changes in processes, training, job content, and performance management to fully leverage and utilize data and analytics.

Analytics is a core competency that our workforce needs to master. We need all employees and managers to be adept and competent in analytics. 

Budgets are a roadblock to success, if you allow them to be. Set up your team, hire the right people, and put the budgeting cycle on autopilot. This approach saves you time, money, and anguish. 

Successful analytics and AI teams routinely integrate data from disparate sources, both internal and external. Collecting these sources of data will span a wide range of departments in the company. 

The first project you do with a new functional area that you do not have an existing relationship with should be a short project. Provide high visibility to your management team, to the management team of the functional area, and to the executive leadership team. This institutional transparency is best achieved through written, verbal, and personal communication. 

During the early stages of analytics process, do not try to limit the scope of investigation too narrowly. Iterative cycles, trial and error, and a bit of patience is required.

These issues can only be overcome in collaboration with the functional sponsors that you and your team are engaged with. You may need only their agreement. You may need their agreement and active sponsorship. You may need all of those previous elements and budgetary support too. No matter what level of support you require, it will only come from fully engaging.

----

Numerous links are provided in this post and a great deal of credit is owed to the following authors and their recent books:

> Thompson, John K.. Building Analytics Teams: Harnessing analytics and artificial intelligence for business improvement (pp. 215-245). Packt Publishing. Kindle Edition

> Provost, Foster and Fawcett, Tom. Data Science for Business: What you need to know about data mining and data-analytic thinking. O'Reilly

> Davenport, Thomas H.. Competing on Analytics: The New Science of Winning. Harvard Business Review Press

----

### Did you find this page helpful? Consider sharing it 🙌

